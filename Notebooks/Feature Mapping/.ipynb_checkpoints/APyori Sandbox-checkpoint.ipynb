{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from csv import reader\n",
    "from csv import writer\n",
    "import custom_models as cm\n",
    "from sklearn import tree\n",
    "from scipy.stats import uniform, norm\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, VarianceThreshold, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from XLB import *\n",
    "import xlb_hyperparamsearch as xlbh\n",
    "from apyori import apriori\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from files\n",
    "x_train, y_train = extract_data(\"FinalTrainingSet.csv\")\n",
    "x_val, y_val = extract_data(\"Validation Set.csv\")\n",
    "\n",
    "# scale data values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "# feature selection\n",
    "num_features = 69\n",
    "feat_sel = VarianceThreshold()\n",
    "x_train = feat_sel.fit_transform(x_train)\n",
    "feat_sel_2 = SelectKBest(chi2,k=num_features)\n",
    "x_train = feat_sel_2.fit_transform(x_train,y_train)\n",
    "# print(feat_sel_2.get_support())\n",
    "x_val = feat_sel_2.transform(feat_sel.transform(x_val))\n",
    "\n",
    "rand_seed = 3454132\n",
    "\n",
    "oversampler = SMOTE(sampling_strategy=\"not majority\",random_state=rand_seed)\n",
    "x_smote, y_smote = oversampler.fit_resample(x_train,y_train)\n",
    "# print(x_smote.shape,y_smote.shape)\n",
    "\n",
    "oversampler = RandomOverSampler(sampling_strategy=\"not majority\",random_state=rand_seed)\n",
    "x_os, y_os = oversampler.fit_resample(x_train,y_train)\n",
    "# print(x_os.shape,y_os.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MOVING FEATURE HEADERS INTO A LIST\n",
    "import csv\n",
    "\n",
    "f = open(\"FinalTrainingSet.csv\")\n",
    "reader = csv.reader(f)\n",
    "features = next(reader)\n",
    "row = list(reader)\n",
    "\n",
    "csv_temp = pd.read_csv(\"FinalTrainingSet.csv\")\n",
    "Theme_numbered = csv_temp['Theme(Numbered)'].tolist()\n",
    "Theme_numbered = np.asarray(Theme_numbered) \n",
    "\n",
    "# print(Theme_numbered.shape)\n",
    "# x_train = np.append(x_train, Theme_numbered.reshape(Theme_numbered.shape[0], 1), axis=1)\n",
    "# print(x_train.shape)\n",
    "\n",
    "# x_train = np.delete(x_train, 69, axis=1)\n",
    "\n",
    "#Deleting everything except features from the dataset\n",
    "features.remove(\"Row Labels\")\n",
    "features.remove(\"Theme\")\n",
    "features.remove(\"Theme(Numbered)\")\n",
    "# print(len(features))\n",
    "#Retained features after selection\n",
    "selected_feats = feat_sel_2.get_support(True)\n",
    "\n",
    "for ind, ft in sorted(enumerate(features), reverse=True): \n",
    "    if ind not in selected_feats:\n",
    "        del features[ind]  \n",
    "        \n",
    "# np.append(x_train, Theme_numbered)\n",
    "features.append('Theme_numbered')\n",
    "\n",
    "new_column = pd.DataFrame({'Theme_numbered': Theme_numbered}) \n",
    "csv_temp = csv_temp.merge(new_column, left_index = True, right_index = True)\n",
    "\n",
    "column = csv_temp.Theme_numbered\n",
    "\n",
    "# print(features)\n",
    "row_count = len(row)\n",
    "f.close()\n",
    " \n",
    "# print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 / 300\n",
      "Best Result: 0.00\n",
      "Iteration 10 / 300\n",
      "Best Result: 0.00\n",
      "Iteration 15 / 300\n",
      "Best Result: 0.00\n",
      "Iteration 20 / 300\n",
      "Best Result: 0.00\n",
      "Iteration 25 / 300\n",
      "Best Result: 0.00\n",
      "Iteration 30 / 300\n",
      "Best Result: 0.00\n",
      "Iteration 35 / 300\n",
      "Best Result: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-7f5bd6f4cd07>\", line 30, in <module>\n",
      "    verbose=True, num_iter=300,interval=5, random_state=696969\n",
      "  File \"D:\\DLSU\\Research Work\\XLB\\XLB48\\Notebooks\\Feature Mapping\\xlb_hyperparamsearch.py\", line 83, in hyperparameter_search\n",
      "    result, cur_model = cross_validation(num_folds,model,params,X,y)\n",
      "  File \"D:\\DLSU\\Research Work\\XLB\\XLB48\\Notebooks\\Feature Mapping\\xlb_hyperparamsearch.py\", line 35, in cross_validation\n",
      "    model.train(np.array(trainlist),np.array(labellist))\n",
      "  File \"D:\\DLSU\\Research Work\\XLB\\XLB48\\Notebooks\\Feature Mapping\\custom_models.py\", line 273, in train\n",
      "    ante_support=ruleset.support\n",
      "  File \"D:\\DLSU\\Research Work\\XLB\\XLB48\\Notebooks\\Feature Mapping\\custom_models.py\", line 37, in __init__\n",
      "    self.compute_confidence(data,labels)\n",
      "  File \"D:\\DLSU\\Research Work\\XLB\\XLB48\\Notebooks\\Feature Mapping\\custom_models.py\", line 61, in compute_confidence\n",
      "    for i,row in enumerate(data):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 195, in __getattribute__\n",
      "    return getattr(getmod(), name)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 179, in getmod\n",
      "    x = importobj(modpath, None)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 69, in importobj\n",
      "    module = __import__(modpath, None, None, ['__doc__'])\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pytest.py\", line 6, in <module>\n",
      "    from _pytest.assertion import register_assert_rewrite\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\_pytest\\assertion\\__init__.py\", line 7, in <module>\n",
      "    from _pytest.assertion import truncate\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 963, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 906, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1280, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1252, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1364, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 81, in _path_stat\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "if verbose:\n",
    "    print(\"MARK 0\")\n",
    "num_folds = 5\n",
    "model = cm.APyoriAdapter(params={})\n",
    "if verbose:\n",
    "    print(\"MARK 1\")\n",
    "emotions = [\"IsCalm\", \"IsCheerful\", \"IsBravery\", \"IsFearful\", \"IsLove\", \"IsSadness\"]\n",
    "label_supp = [0.3117,  0.1372, 0.1397,  0.2469, 0.0673, 0.0973]\n",
    "if verbose:\n",
    "    print(\"MARK 2\")\n",
    "parameters = {\n",
    "    \"num_features\" : 69,\n",
    "    \"thresh_mean\" : 0.5,\n",
    "    \"thresh_std\" : 0.15,\n",
    "    \"min_support_lo\" : 0.16,\n",
    "    \"min_support_hi\" : 0.22,\n",
    "#     \"min_confidence_lo\" : 0.036,\n",
    "#     \"min_confidence_hi\" : 0.539,\n",
    "    \"min_confidence_lo\" : 0.0,\n",
    "    \"min_confidence_hi\" : 0.0,\n",
    "    \"col_names\" : features[:-1],\n",
    "    \"label_names\" : emotions,\n",
    "    \"label_support\" : label_supp,\n",
    "    \"min_rules_lo\" : 6,\n",
    "    \"min_rules_hi\" : 30\n",
    "}\n",
    "if verbose:\n",
    "    print(\"MARK 3\")\n",
    "hyperparams, result, model = xlbh.hyperparameter_search(\n",
    "    num_folds=num_folds,model=model,parameters=parameters,X=x_train,y=y_train,\\\n",
    "    verbose=True, num_iter=300,interval=5, random_state=696969\n",
    ")\n",
    "if verbose:\n",
    "    print(\"MARK 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"rules.txt\",\"w\") as fOut:\n",
    "    np.random.seed(69420)\n",
    "    ruleset = model.ruleset\n",
    "    fOut.write(\"{}\\n\".format(\"\\n\\n\".join([x.__str__() for x in ruleset])))\n",
    "    print(\"Average Interestingness: {:.2f}\".format(model.evaluate()))\n",
    "    probas = model.predict_proba(x_val)\n",
    "    labels = model.predict(x_val)\n",
    "    acc = model.score(x_val,y_val - 1)\n",
    "    print(probas)\n",
    "    print(labels)\n",
    "    print(\"Accuracy: {:.2f}\".format(acc))\n",
    "    print(labels,y_val - 1)\n",
    "    print(\"F1-score: {}\".format(f1_score(labels,list(map(int,y_val - 1)),average=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in hyperparams.items():\n",
    "    print(\"{} -> {}\".format(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
