{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from csv import reader\n",
    "from csv import writer\n",
    "import custom_models as cm\n",
    "from sklearn import tree\n",
    "from scipy.stats import uniform, norm\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, VarianceThreshold, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from XLB import *\n",
    "from apyori import apriori\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True False False False False False False False\n",
      "  True False False False False False  True False False False  True False\n",
      " False False  True False False False False False  True False False False\n",
      "  True False False False False False  True False False False  True False\n",
      " False False  True False False False False False False  True False  True\n",
      "  True  True  True False False False  True  True  True False  True  True\n",
      " False False  True  True  True False  True False False  True  True False\n",
      " False  True  True False False False  True  True  True False  True  True\n",
      " False False  True  True  True False  True False False False False False\n",
      " False False  True False  True False  True False  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True False  True False  True  True\n",
      " False]\n",
      "(750, 69) (750,)\n",
      "(750, 69) (750,)\n"
     ]
    }
   ],
   "source": [
    "# extract data from files\n",
    "x_train, y_train = extract_data(\"FinalTrainingSet.csv\")\n",
    "x_val, y_val = extract_data(\"Validation Set.csv\")\n",
    "\n",
    "# scale data values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "# feature selection\n",
    "num_features = 69\n",
    "feat_sel = VarianceThreshold()\n",
    "x_train = feat_sel.fit_transform(x_train)\n",
    "feat_sel_2 = SelectKBest(chi2,k=num_features)\n",
    "x_train = feat_sel_2.fit_transform(x_train,y_train)\n",
    "print(feat_sel_2.get_support())\n",
    "x_val = feat_sel_2.transform(feat_sel.transform(x_val))\n",
    "\n",
    "rand_seed = 3454132\n",
    "\n",
    "oversampler = SMOTE(sampling_strategy=\"not majority\",random_state=rand_seed)\n",
    "x_smote, y_smote = oversampler.fit_resample(x_train,y_train)\n",
    "print(x_smote.shape,y_smote.shape)\n",
    "\n",
    "oversampler = RandomOverSampler(sampling_strategy=\"not majority\",random_state=rand_seed)\n",
    "x_os, y_os = oversampler.fit_resample(x_train,y_train)\n",
    "print(x_os.shape,y_os.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 70)\n",
      "['Tempo', 'Arousal', 'IsMajor', 'IsMinor', 'IsDissonant', 'Derivative of Root Mean Square Overall Standard Deviation', 'Derivative of Running Mean of Root Mean Square Overall Standard Deviation', 'Derivative of Running Mean of Spectral Flux Overall Standard Deviation', 'Derivative of Running Mean of Spectral Variability Overall Standard Deviation', 'Derivative of Spectral Flux Overall Standard Deviation', 'Derivative of Spectral Variability Overall Standard Deviation', 'Derivative of Standard Deviation of Root Mean Square Overall Standard Deviation', 'Derivative of Standard Deviation of Spectral Flux Overall Standard Deviation', 'Derivative of Standard Deviation of Spectral Variability Overall Standard Deviation', 'Fraction Of Low Energy Windows Overall Average', 'Magnitude Spectrum Overall Average', 'Magnitude Spectrum Overall Standard Deviation', 'Power Spectrum Overall Average', 'Power Spectrum Overall Standard Deviation', 'Running Mean of Compactness Overall Standard Deviation', 'Running Mean of Fraction Of Low Energy Windows Overall Average', 'Running Mean of Fraction Of Low Energy Windows Overall Standard Deviation', 'Running Mean of Root Mean Square Overall Standard Deviation', 'Running Mean of Spectral Centroid Overall Average', 'Running Mean of Spectral Flux Overall Standard Deviation', 'Running Mean of Spectral Rolloff Point Overall Average', 'Running Mean of Spectral Rolloff Point Overall Standard Deviation', 'Running Mean of Spectral Variability Overall Standard Deviation', 'Spectral Centroid Overall Average', 'Spectral Centroid Overall Standard Deviation', 'Spectral Rolloff Point Overall Average', 'Spectral Rolloff Point Overall Standard Deviation', 'Standard Deviation of Compactness Overall Standard Deviation', 'Standard Deviation of Fraction Of Low Energy Windows Overall Average', 'Standard Deviation of Fraction Of Low Energy Windows Overall Standard Deviation', 'Standard Deviation of Root Mean Square Overall Standard Deviation', 'Standard Deviation of Spectral Centroid Overall Average', 'Standard Deviation of Spectral Flux Overall Standard Deviation', 'Standard Deviation of Spectral Rolloff Point Overall Average', 'Standard Deviation of Spectral Rolloff Point Overall Standard Deviation', 'Standard Deviation of Spectral Variability Overall Standard Deviation', 'Beat Histogram Overall Standard Deviation', 'Beat Sum Overall Standard Deviation', 'ConstantQ Overall Standard Deviation', 'Derivative of Beat Sum Overall Standard Deviation', 'Derivative of LPC Overall Standard Deviation', 'Derivative of Method of Moments Overall Average', 'Derivative of Method of Moments Overall Standard Deviation', 'Derivative of MFCC Overall Average', 'Derivative of MFCC Overall Standard Deviation', 'Derivative of Partial Based Spectral Centroid Overall Average', 'Derivative of Partial Based Spectral Centroid Overall Standard Deviation', 'Derivative of Partial Based Spectral Flux Overall Average', 'Derivative of Partial Based Spectral Flux Overall Standard Deviation', 'Derivative of Peak Based Spectral Smoothness Overall Average', 'Derivative of Peak Based Spectral Smoothness Overall Standard Deviation', 'Derivative of Relative Difference Function Overall Average', 'Derivative of Relative Difference Function Overall Standard Deviation', 'Derivative of Running Mean of Beat Sum Overall Average', 'Derivative of Running Mean of Beat Sum Overall Standard Deviation', 'Derivative of Running Mean of LPC Overall Average', 'Derivative of Running Mean of LPC Overall Standard Deviation', 'Derivative of Running Mean of Method of Moments Overall Average', 'Derivative of Running Mean of Method of Moments Overall Standard Deviation', 'Derivative of Running Mean of MFCC Overall Average', 'Derivative of Running Mean of MFCC Overall Standard Deviation', 'Derivative of Running Mean of Partial Based Spectral Centroid Overall Standard Deviation', 'Derivative of Running Mean of Partial Based Spectral Flux Overall Standard Deviation', 'Derivative of Running Mean of Peak Based Spectral Smoothness Overall Average', 'Theme_numbered']\n",
      "(401, 70)\n"
     ]
    }
   ],
   "source": [
    "#MOVING FEATURE HEADERS INTO A LIST\n",
    "import csv\n",
    "\n",
    "f = open(\"FinalTrainingSet.csv\")\n",
    "reader = csv.reader(f)\n",
    "features = next(reader)\n",
    "row = list(reader)\n",
    "\n",
    "csv_temp = pd.read_csv(\"FinalTrainingSet.csv\")\n",
    "Theme_numbered = csv_temp['Theme(Numbered)'].tolist()\n",
    "Theme_numbered = np.asarray(Theme_numbered) \n",
    "\n",
    "# print(Theme_numbered.shape)\n",
    "x_train = np.append(x_train, Theme_numbered.reshape(Theme_numbered.shape[0], 1), axis=1)\n",
    "print(x_train.shape)\n",
    "\n",
    "# x_train = np.delete(x_train, 69, axis=1)\n",
    "\n",
    "#Deleting everything except features from the dataset\n",
    "features.remove(\"Row Labels\")\n",
    "features.remove(\"Theme\")\n",
    "features.remove(\"Theme(Numbered)\")\n",
    "# print(len(features))\n",
    "#Retained features after selection\n",
    "selected_feats = feat_sel_2.get_support(True)\n",
    "\n",
    "for ind, ft in sorted(enumerate(features), reverse=True): \n",
    "    if ind not in selected_feats:\n",
    "        del features[ind]  \n",
    "        \n",
    "# np.append(x_train, Theme_numbered)\n",
    "features.append('Theme_numbered')\n",
    "\n",
    "new_column = pd.DataFrame({'Theme_numbered': Theme_numbered}) \n",
    "csv_temp = csv_temp.merge(new_column, left_index = True, right_index = True)\n",
    "\n",
    "column = csv_temp.Theme_numbered\n",
    "\n",
    "print(features)\n",
    "row_count = len(row)\n",
    "f.close()\n",
    " \n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Interestingness: 0.00\n"
     ]
    }
   ],
   "source": [
    "with open(\"rules.txt\",\"w\") as fOut:\n",
    "    np.random.seed(69420)\n",
    "    emotion_val = [1,2,3,4,5,6]\n",
    "    emotions = [\"IsCalm\", \"IsCheerful\", \"IsBravery\", \"IsFearful\", \"IsLove\", \"IsSadness\"]\n",
    "    min_support = 0.22\n",
    "    label_supp = [0.3117,  0.1372, 0.1397,  0.2469, 0.0673, 0.0973]\n",
    "    model = cm.APyoriAdapter({\n",
    "        \"thresholds\" : np.random.normal(0.5, 0.15, num_features), # randomize for hyperparameter search\n",
    "        \"col_names\" : features,\n",
    "        \"label_names\" : emotions,\n",
    "        \"label_support\" : label_supp,\n",
    "        \"min_support\" : min_support # randomize for hyperparameter search\n",
    "    })\n",
    "\n",
    "    ruleset = model.train(x_train)\n",
    "#     print(\"{}\\n\".format(\"\\n\\n\".join([x.__str__() for x in ruleset])))\n",
    "    fOut.write(\"{}\\n\".format(\"\\n\\n\".join([x.__str__() for x in ruleset])))\n",
    "    print(\"Average Interestingness: {:.2f}\".format(model.evaluate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
