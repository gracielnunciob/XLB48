{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from csv import reader\n",
    "from csv import writer\n",
    "import custom_models as cm\n",
    "from sklearn import tree\n",
    "from scipy.stats import uniform, norm\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, VarianceThreshold, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from XLB import *\n",
    "import xlb_hyperparamsearch as xlbh\n",
    "from apyori import apriori\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from files\n",
    "x_train, y_train = extract_data(\"FinalTrainingSet.csv\")\n",
    "x_val, y_val = extract_data(\"Validation Set.csv\")\n",
    "\n",
    "# scale data values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "# feature selection\n",
    "num_features = 69\n",
    "feat_sel = VarianceThreshold()\n",
    "x_train = feat_sel.fit_transform(x_train)\n",
    "feat_sel_2 = SelectKBest(chi2,k=num_features)\n",
    "x_train = feat_sel_2.fit_transform(x_train,y_train)\n",
    "# print(feat_sel_2.get_support())\n",
    "x_val = feat_sel_2.transform(feat_sel.transform(x_val))\n",
    "\n",
    "rand_seed = 3454132\n",
    "\n",
    "oversampler = SMOTE(sampling_strategy=\"not majority\",random_state=rand_seed)\n",
    "x_smote, y_smote = oversampler.fit_resample(x_train,y_train)\n",
    "# print(x_smote.shape,y_smote.shape)\n",
    "\n",
    "oversampler = RandomOverSampler(sampling_strategy=\"not majority\",random_state=rand_seed)\n",
    "x_os, y_os = oversampler.fit_resample(x_train,y_train)\n",
    "# print(x_os.shape,y_os.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MOVING FEATURE HEADERS INTO A LIST\n",
    "import csv\n",
    "\n",
    "f = open(\"FinalTrainingSet.csv\")\n",
    "reader = csv.reader(f)\n",
    "features = next(reader)\n",
    "row = list(reader)\n",
    "\n",
    "csv_temp = pd.read_csv(\"FinalTrainingSet.csv\")\n",
    "Theme_numbered = csv_temp['Theme(Numbered)'].tolist()\n",
    "Theme_numbered = np.asarray(Theme_numbered) \n",
    "\n",
    "# print(Theme_numbered.shape)\n",
    "# x_train = np.append(x_train, Theme_numbered.reshape(Theme_numbered.shape[0], 1), axis=1)\n",
    "# print(x_train.shape)\n",
    "\n",
    "# x_train = np.delete(x_train, 69, axis=1)\n",
    "\n",
    "#Deleting everything except features from the dataset\n",
    "features.remove(\"Row Labels\")\n",
    "features.remove(\"Theme\")\n",
    "features.remove(\"Theme(Numbered)\")\n",
    "# print(len(features))\n",
    "#Retained features after selection\n",
    "selected_feats = feat_sel_2.get_support(True)\n",
    "\n",
    "for ind, ft in sorted(enumerate(features), reverse=True): \n",
    "    if ind not in selected_feats:\n",
    "        del features[ind]  \n",
    "        \n",
    "# np.append(x_train, Theme_numbered)\n",
    "features.append('Theme_numbered')\n",
    "\n",
    "new_column = pd.DataFrame({'Theme_numbered': Theme_numbered}) \n",
    "csv_temp = csv_temp.merge(new_column, left_index = True, right_index = True)\n",
    "\n",
    "column = csv_temp.Theme_numbered\n",
    "\n",
    "# print(features)\n",
    "row_count = len(row)\n",
    "f.close()\n",
    " \n",
    "# print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 / 200\n",
      "Best Result: 0.43\n",
      "Iteration 10 / 200\n",
      "Best Result: 0.43\n",
      "Iteration 15 / 200\n",
      "Best Result: 0.43\n",
      "Iteration 20 / 200\n",
      "Best Result: 0.43\n",
      "Iteration 25 / 200\n",
      "Best Result: 0.43\n",
      "Iteration 30 / 200\n",
      "Best Result: 0.43\n",
      "Iteration 35 / 200\n",
      "Best Result: 0.44\n",
      "Iteration 40 / 200\n",
      "Best Result: 0.44\n",
      "Iteration 45 / 200\n",
      "Best Result: 0.44\n",
      "Iteration 50 / 200\n",
      "Best Result: 0.44\n",
      "Iteration 55 / 200\n",
      "Best Result: 0.44\n",
      "Iteration 60 / 200\n",
      "Best Result: 0.44\n",
      "Iteration 65 / 200\n",
      "Best Result: 0.44\n",
      "Iteration 70 / 200\n",
      "Best Result: 0.44\n",
      "Iteration 75 / 200\n",
      "Best Result: 0.44\n",
      "Iteration 80 / 200\n",
      "Best Result: 0.44\n",
      "Iteration 85 / 200\n",
      "Best Result: 0.44\n"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "if verbose:\n",
    "    print(\"MARK 0\")\n",
    "num_folds = 5\n",
    "model = cm.APyoriAdapter(params={})\n",
    "if verbose:\n",
    "    print(\"MARK 1\")\n",
    "emotions = [\"IsCalm\", \"IsCheerful\", \"IsBravery\", \"IsFearful\", \"IsLove\", \"IsSadness\"]\n",
    "label_supp = [0.3117,  0.1372, 0.1397,  0.2469, 0.0673, 0.0973]\n",
    "if verbose:\n",
    "    print(\"MARK 2\")\n",
    "parameters = {\n",
    "    \"num_features\" : 69,\n",
    "    \"thresh_mean\" : 0.5,\n",
    "    \"thresh_std\" : 0.15,\n",
    "    \"min_support_lo\" : 0.16,\n",
    "    \"min_support_hi\" : 0.22,\n",
    "    \"min_confidence_lo\" : 0.036,\n",
    "    \"min_confidence_hi\" : 0.739,\n",
    "    \"col_names\" : features[:-1],\n",
    "    \"label_names\" : emotions,\n",
    "    \"label_support\" : label_supp\n",
    "}\n",
    "if verbose:\n",
    "    print(\"MARK 3\")\n",
    "hyperparams, result, model = xlbh.hyperparameter_search(\n",
    "    num_folds=num_folds,model=model,parameters=parameters,X=x_train,y=y_train,\\\n",
    "    verbose=True, interval=5\n",
    ")\n",
    "if verbose:\n",
    "    print(\"MARK 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"rules.txt\",\"w\") as fOut:\n",
    "    np.random.seed(69420)\n",
    "    ruleset = model.ruleset\n",
    "    fOut.write(\"{}\\n\".format(\"\\n\\n\".join([x.__str__() for x in ruleset])))\n",
    "    print(\"Average Interestingness: {:.2f}\".format(model.evaluate()))\n",
    "    probas = model.predict_proba(x_val)\n",
    "    labels = model.predict(x_val)\n",
    "    acc = model.score(x_val,y_val - 1)\n",
    "    print(probas)\n",
    "    print(labels)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
