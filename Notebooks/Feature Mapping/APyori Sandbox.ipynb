{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from csv import reader\n",
    "from csv import writer\n",
    "import custom_models as cm\n",
    "from sklearn import tree\n",
    "from scipy.stats import uniform, norm\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, VarianceThreshold, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from XLB import *\n",
    "import xlb_hyperparamsearch as xlbh\n",
    "from apyori import apriori\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from files\n",
    "x_train, y_train = extract_data(\"FinalTrainingSet.csv\")\n",
    "x_val, y_val = extract_data(\"Validation Set.csv\")\n",
    "\n",
    "# scale data values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "# feature selection\n",
    "num_features = 8\n",
    "feat_sel = VarianceThreshold()\n",
    "x_train = feat_sel.fit_transform(x_train)\n",
    "feat_sel_2 = SelectKBest(chi2,k=num_features)\n",
    "x_train = feat_sel_2.fit_transform(x_train,y_train)\n",
    "# print(feat_sel_2.get_support())\n",
    "x_val = feat_sel_2.transform(feat_sel.transform(x_val))\n",
    "\n",
    "rand_seed = 3454132\n",
    "\n",
    "oversampler = SMOTE(sampling_strategy=\"not majority\",random_state=rand_seed)\n",
    "x_smote, y_smote = oversampler.fit_resample(x_train,y_train)\n",
    "# print(x_smote.shape,y_smote.shape)\n",
    "\n",
    "oversampler = RandomOverSampler(sampling_strategy=\"not majority\",random_state=rand_seed)\n",
    "x_os, y_os = oversampler.fit_resample(x_train,y_train)\n",
    "# print(x_os.shape,y_os.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MOVING FEATURE HEADERS INTO A LIST\n",
    "import csv\n",
    "\n",
    "f = open(\"FinalTrainingSet.csv\")\n",
    "reader = csv.reader(f)\n",
    "features = next(reader)\n",
    "row = list(reader)\n",
    "\n",
    "csv_temp = pd.read_csv(\"FinalTrainingSet.csv\")\n",
    "Theme_numbered = csv_temp['Theme(Numbered)'].tolist()\n",
    "Theme_numbered = np.asarray(Theme_numbered) \n",
    "\n",
    "# print(Theme_numbered.shape)\n",
    "# x_train = np.append(x_train, Theme_numbered.reshape(Theme_numbered.shape[0], 1), axis=1)\n",
    "# print(x_train.shape)\n",
    "\n",
    "# x_train = np.delete(x_train, 69, axis=1)\n",
    "\n",
    "#Deleting everything except features from the dataset\n",
    "features.remove(\"Row Labels\")\n",
    "features.remove(\"Theme\")\n",
    "features.remove(\"Theme(Numbered)\")\n",
    "# print(len(features))\n",
    "#Retained features after selection\n",
    "selected_feats = feat_sel_2.get_support(True)\n",
    "\n",
    "for ind, ft in sorted(enumerate(features), reverse=True): \n",
    "    if ind not in selected_feats:\n",
    "        del features[ind]  \n",
    "        \n",
    "# np.append(x_train, Theme_numbered)\n",
    "features.append('Theme_numbered')\n",
    "\n",
    "new_column = pd.DataFrame({'Theme_numbered': Theme_numbered}) \n",
    "csv_temp = csv_temp.merge(new_column, left_index = True, right_index = True)\n",
    "\n",
    "column = csv_temp.Theme_numbered\n",
    "\n",
    "# print(features)\n",
    "row_count = len(row)\n",
    "f.close()\n",
    " \n",
    "# print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result = 0.9011176446401608\n",
      "Result = 0.9024301316253851\n",
      "Result = 0.9024301316253851\n",
      "Result = 0.9031503239382133\n",
      "Result = 0.9015840283030736\n",
      "Result = 0.9035728240054514\n",
      "Result = 0.9024301316253851\n",
      "Result = 0.9020076315581466\n",
      "Result = 0.9035728240054514\n",
      "Iteration 10 / 200\n",
      "Best Result: 0.90\n",
      "Result = 0.9020076315581466\n"
     ]
    }
   ],
   "source": [
    "emotions = [\"IsCalm\", \"IsCheerful\", \"IsBravery\", \"IsFearful\", \"IsLove\", \"IsSadness\"]\n",
    "label_supp = [0.3117,  0.1372, 0.1397,  0.2469, 0.0673, 0.0973]\n",
    "    \n",
    "for theme in range(1,7):\n",
    "    verbose = False\n",
    "    num_folds = 5\n",
    "    model = cm.APyoriAdapter(params={})\n",
    "    targ_supp = [1 - label_supp[theme - 1],label_supp[theme - 1]]\n",
    "    parameters = {\n",
    "        \"num_features\" : num_features,\n",
    "        \"thresh_mean\" : 0.5,\n",
    "        \"thresh_std\" : 0.3,\n",
    "        \"min_support_lo\" : 0.005,\n",
    "        \"min_support_hi\" : 0.01,\n",
    "#         \"min_confidence_lo\" : 0.036,\n",
    "#         \"min_confidence_hi\" : 0.539,\n",
    "        \"min_confidence_lo\" : 0.00,\n",
    "        \"min_confidence_hi\" : 0.00,\n",
    "        \"col_names\" : features[:-1],\n",
    "        \"label_names\" : [\"IsNot{}\".format(emotions[theme-1][2:]),emotions[theme - 1]],\n",
    "        \"label_support\" : targ_supp,\n",
    "        \"min_rules_lo\" : 4,\n",
    "        \"min_rules_hi\" : 8\n",
    "    }\n",
    "    y_targ = np.reshape(np.array([y_smote == theme]),(750,))\n",
    "    hyperparams, result, model = xlbh.hyperparameter_search(\n",
    "        num_folds=num_folds,model=model,parameters=parameters,X=x_smote,\n",
    "        y=y_targ,verbose=True, num_iter=200,interval=10,random_state=69420\n",
    "    )\n",
    "    \n",
    "    with open(\"rules{}.txt\".format(emotions[theme - 1]),\"w\") as fOut:\n",
    "        ruleset = model.ruleset\n",
    "        fOut.write(\"{}\\n\".format(\"\\n\\n\".join([x.__str__() for x in ruleset])))\n",
    "        print(\"Average Interestingness: {:.2f}\".format(model.evaluate()))\n",
    "        probas = model.predict_proba(x_val)\n",
    "        labels = model.predict(x_val)\n",
    "        acc = model.score(x_val,y_val == theme)\n",
    "        print(\"Stats for {}\".format(emotions[theme - 1]))\n",
    "#         print(probas)\n",
    "#         print(labels,y_val == theme)\n",
    "        print(\"Accuracy: {:.2f}\".format(acc))\n",
    "        print(\"F1-score: {}\".format(f1_score(\n",
    "            labels,list(map(int,y_val == theme))\n",
    "        )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in hyperparams.items():\n",
    "    print(\"{} -> {}\".format(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
