{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decison Tree Classifier for Classifying Music Emotions\n",
    "---\n",
    "## About the Dataset\n",
    "\n",
    "For this experiment, our dataset contains 267 music samples that were labelled by 2 music experts. The dataset has a combination of high level and low level features. The high level features are tempo, arousal, and scale, which were all labelled by the music experts. The low level features were extracted from the music samples using the JAudio software.\n",
    "\n",
    "---\n",
    "## Libraries\n",
    "\n",
    "We used the pandas and csv libraries to load the dataset, which is a csv file. Then we used numpy to manipulate the loaded dataset. We used the sci kit learn library for the decision tree algorithm. The XLB file is where we modularized the training and validation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import uniform, norm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from XLB import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the data from the csv file and preprocess it by removing the header row and the filename column this is done by the extract_data function from the XLB file which takes the filename of the dataset as a parameter\n",
    "\n",
    "---\n",
    "\n",
    "After the initial preprocessing step, we sperated the music features and the labelled emotion into the x_train and y_train arrays respectively. We also used the scikit learn min max scaler to normalize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 327)\n",
      "(401, 324)\n",
      "(401,)\n",
      "(21, 327)\n",
      "(21, 324)\n",
      "(21,)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = extract_data(\"FinalTrainingSet.csv\")\n",
    "x_val, y_val = extract_data(\"Validation Set.csv\")\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "\n",
    "scaler_val = MinMaxScaler()\n",
    "scaler.fit(x_val)\n",
    "x_val = scaler.transform(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform different methods to deal with imbalanced datasets. We used the oversampling and SMOTE methodology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 324) (750,)\n",
      "(750, 324) (750,)\n"
     ]
    }
   ],
   "source": [
    "rand_seed = 3454132\n",
    "\n",
    "oversampler = SMOTE(sampling_strategy=\"not majority\",random_state=rand_seed)\n",
    "\n",
    "x_smote, y_smote = oversampler.fit_resample(x_train,y_train)\n",
    "\n",
    "print(x_smote.shape,y_smote.shape)\n",
    "\n",
    "oversampler = RandomOverSampler(sampling_strategy=\"not majority\",random_state=rand_seed)\n",
    "\n",
    "x_os, y_os = oversampler.fit_resample(x_train,y_train)\n",
    "\n",
    "print(x_os.shape,y_os.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells are the experiments we ran with the default dataset, oversampled version, and SMOTE version using random search as the hyperparameter search algorithm\n",
    "\n",
    "---\n",
    "This cell instantiates the decison tree object and the hyperparameter search object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTree\n",
    "random_search_iterations = 1000\n",
    "n_splits = 10\n",
    "rand_seed = 3249807\n",
    "\n",
    "parameters = {\n",
    "    'criterion':[\"gini\", \"entropy\"], \n",
    "    'splitter':[\"best\", \"random\"], \n",
    "    'max_depth':range(1, 10), \n",
    "    'min_samples_split':uniform(loc=0,scale=1.0)\n",
    "}\n",
    "\n",
    "# train classifier for SMOTE data\n",
    "dt = tree.DecisionTreeClassifier(random_state=rand_seed)\n",
    "rscv = RandomizedSearchCV(dt, parameters,cv=n_splits, random_state=rand_seed, n_iter=random_search_iterations,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is trained using the imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_res(\"Vanilla\",x_train,y_train,rscv)\n",
    "disp_tree(dt,x_train,y_train,\"FinalTrainingSet.csv\")\n",
    "test_res(\"Vanilla\",x_val,y_val,rscv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is trained using the oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_res(\"Random Oversampling\",x_os,y_os,rscv)\n",
    "disp_tree(dt,x_os,y_os,\"FinalTrainingSet.csv\")\n",
    "test_res(\"Random Oversampling\",x_val,y_val,rscv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is trained using the SMOTE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_res(\"SMOTE\",x_smote,y_smote,rscv)\n",
    "disp_tree(dt,x_smote,y_smote,\"FinalTrainingSet.csv\")\n",
    "test_res(\"SMOTE\",x_val,y_val,rscv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
