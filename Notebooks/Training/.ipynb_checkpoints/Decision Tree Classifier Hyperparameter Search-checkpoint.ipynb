{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decison Tree Classifier for Classifying Music Emotions\n",
    "---\n",
    "## About the Dataset\n",
    "\n",
    "For this experiment, our dataset contains 267 music samples that were labelled by 2 music experts. The dataset has a combination of high level and low level features. The high level features are tempo, arousal, and scale, which were all labelled by the music experts. The low level features were extracted from the music samples using the JAudio software.\n",
    "\n",
    "---\n",
    "## Libraries\n",
    "\n",
    "We used the pandas and csv libraries to load the dataset, which is a csv file. Then we used numpy to manipulate the loaded dataset. We used the sci kit learn library for the decision tree algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import uniform, norm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the data from the csv file and preprocess it by removing the header row and the filename column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []    \n",
    "f = open(\"HighAndLowFeatures(edited).csv\",\"r\")\n",
    "d_reader = csv.reader(f,delimiter=\",\",quotechar=\"\\\"\")\n",
    "first = True\n",
    "for line in d_reader:\n",
    "    if first:\n",
    "        first = False\n",
    "        continue\n",
    "    data.append(line)\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the initial preprocessing step, we sperated the music features and the labelled emotion into the x_train and y_train arrays respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.empty((0,340))\n",
    "y_train = np.array([])\n",
    "\n",
    "for line in data:\n",
    "    x_train = np.append(x_train,np.array(list(map(float,line[1:-2]))).reshape((1,340)),axis=0)\n",
    "    y_train = np.append(y_train,int(line[-1]))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform different methods to deal with imbalanced datasets. We used the oversampling *Insert link to oversampling if needed* and SMOTE methodology *Insert link to SMOTE if needed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed = 3454132\n",
    "\n",
    "oversampler = SMOTE(sampling_strategy=\"not majority\",random_state=rand_seed)\n",
    "\n",
    "x_smote, y_smote = oversampler.fit_resample(x_train,y_train)\n",
    "\n",
    "print(x_smote.shape,y_smote.shape)\n",
    "\n",
    "oversampler = RandomOverSampler(sampling_strategy=\"not majority\",random_state=rand_seed)\n",
    "\n",
    "x_os, y_os = oversampler.fit_resample(x_train,y_train)\n",
    "\n",
    "print(x_os.shape,y_os.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we defined a function that will train the model and perform the hyperparameter search. x_train is the input data, y_train is the labels for the input data, and hp_search is the algorithm for hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trains a model using the given data and a hyperparameter search object\n",
    "\n",
    "Parameters:\n",
    "x_train - input data\n",
    "y_train - target labels for data\n",
    "hp_search - model_selection object\n",
    "\n",
    "Returns: best estimator for the given data given the model selector\n",
    "\"\"\"\n",
    "def train_model(x_train,y_train,hp_search):\n",
    "    hp_search.fit(x_train,y_train)\n",
    "    print(\"Best Score: {:.4f}\".format(hp_search.best_score_))\n",
    "    for k,v in hp_search.best_params_.items():\n",
    "        print(\"{} => {}\".format(k,v))\n",
    "    print(\"Splits: {}\".format(hp_search.n_splits_))\n",
    "    y_out = hp_search.predict(x_train)\n",
    "    print(\"Accuracy: {:.4f}%\".format(np.mean(y_out == y_train) * 100.0))\n",
    "    return hp_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function trains the model, using the previously defined train_model function, and displays the confusion matrix of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_res(name,x_train,y_train,model_selector):\n",
    "    print(\"{}:\".format(name))\n",
    "    train_model(x_train,y_train,model_selector)\n",
    "\n",
    "    # display confusion matrix\n",
    "    disp = plot_confusion_matrix(model_selector, x_train, y_train,\n",
    "                                 display_labels=[\"Calm\",\"Cheerful\",\"Bravery\",\"Fearful\",\"Sadness\",\"Love\"],\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true')\n",
    "    # print(y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function displays the decision tree that the model used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_tree(dt,x_train,y_train):\n",
    "    classes = ['Brave', 'Cheerful', 'Fearful', 'Love', 'Sadness', 'Calm']\n",
    "    dt.fit(x_train,y_train)\n",
    "    file = pd.read_csv(\"HighAndLowFeatures(edited).csv\")\n",
    "    features = list(file)\n",
    "    fig, ax = plt.subplots(figsize=(40, 40))\n",
    "    treefig = tree.plot_tree(dt, class_names=classes, feature_names=features[1:-3], fontsize=12, ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells are the experiments we ran with the default dataset, oversampled version, and SMOTE version using random search as the hyperparameter search algorithm\n",
    "\n",
    "---\n",
    "This cell instantiates the decison tree object and the hyperparameter search object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTree\n",
    "random_search_iterations = 1000\n",
    "n_splits = 5\n",
    "rand_seed = 3249807\n",
    "\n",
    "parameters = {\n",
    "    'criterion':[\"gini\", \"entropy\"], \n",
    "    'splitter':[\"best\", \"random\"], \n",
    "    'max_depth':range(1, 10), \n",
    "    'min_samples_split':uniform(loc=0,scale=1.0)\n",
    "}\n",
    "\n",
    "# train classifier for SMOTE data\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "rscv = RandomizedSearchCV(dt, parameters,cv=n_splits, random_state=rand_seed, n_iter=random_search_iterations,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is trained using the default "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_res(\"Vanilla\",x_train,y_train,rscv)\n",
    "disp_tree(dt,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_res(\"Random Oversampling\",x_os,y_os,rscv)\n",
    "disp_tree(dt,x_os,y_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_res(\"SMOTE\",x_smote,y_smote,rscv)\n",
    "disp_tree(dt,x_smote,y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [1,2,3,4,5]\n",
    "print(temp[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
